trainer: Trans1xTrainer
K: 3
rotation_axes: &rotation_axes [0, 0, 1] # horizontal, depth, vertical
body_reference: &body_reference True

# model options
n_joints: 15
seq_len: 64                   # length of motion sequence

# logger options
snapshot_save_iter: 20000     # How often do you want to save trained models
log_iter: 40                  # How often do you want to log the training stats
val_iter: 400
val_batches: 10

# optimization options
max_iter: 200000              # maximum number of training iterations
batch_size: 64                # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0002                    # initial learning rate
lr_policy: step               # learning rate scheduler
step_size: 20000              # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate

trans_gan_w: 2
trans_gan_ls_w: 0
body_gan_w: 0
kl_b_w: 0                     # weight of beta vae loss (kl loss)
kl_m_w: 0                     # weight of beta vae loss (kl loss)
kl_v_w: 0                     # weight of beta vae loss (kl loss)
recon_x_w: 10                 # weight of image reconstruction loss
cross_x_w: 4
recon_v_ls_w: 2
recon_m_ls_w: 2
recon_b_trans_w: 2            # weight of style reconstruction loss
recon_m_trans_w: 2            # weight of content reconstruction loss

triplet_b_w: 10               # weight of body triplet loss
triplet_v_w: 10               # weight of view triplet loss
triplet_margin: 0.2
triplet_neg_range: [0.0, 0.5]

autoencoder:
  cls: Autoencoder3f
  body_reference: *body_reference
  motion_encoder:
    cls: ConvEncoder
    channels: [30, 64, 128, 128]
    padding: 3
    kernel_size: 8
    conv_stride: 2
    conv_pool: null
  body_encoder:
    cls: ConvEncoder
    channels: [28, 64, 128, 256]
    padding: 2
    kernel_size: 7
    conv_stride: 1
    conv_pool: AvgPool1d
    global_pool: avg_pool1d
    n_att: 0
  view_encoder:
    cls: ConvEncoder
    channels: [28, 64, 32, 8]
    padding: 2
    kernel_size: 7
    conv_stride: 1
    conv_pool: MaxPool1d
    global_pool: max_pool1d
    n_att: 0
  decoder:
    channels: [392, 256, 128, 45]
    kernel_size: 7

discriminator:
  encoder_cls: ConvEncoder
  gan_type: lsgan
  channels: [30, 64, 96, 128]
  padding: 3
  kernel_size: 8
  conv_stride: 2
  conv_pool: null
  n_att: 0

body_discriminator:
  gan_type: lsgan
  channels: [512, 128, 32]


# data options
data:
  train_cls: SoloDanceFullDataset1x
  eval_cls: Mixamo2DFullDataset2x
  global_range: [0.5, 2.0]
  local_range: [0.5, 2.0]
  rotation_axes: *rotation_axes
  unit: 128
  train_dir: ./data/solo_dance/train
  test_dir: ./data/mixamo/36_800_24/test
  num_workers: 4
  train_meanpose_path: ./data/mixamo/36_800_24/meanpose_with_view.npy
  train_stdpose_path: ./data/mixamo/36_800_24/stdpose_with_view.npy
  test_meanpose_path: ./data/mixamo/36_800_24/meanpose_with_view.npy
  test_stdpose_path: ./data/mixamo/36_800_24/stdpose_with_view.npy
